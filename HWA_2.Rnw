\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[a4paper, total={6in, 8.1in}]{geometry}
\usepackage{bm}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{graphicx}

\title{Homework Assignment 2 -- Solutions}
\author{Valentin Zulj}
\date{}

\begin{document}

<<include = FALSE>>=
opts_chunk$set(size = "footnotesize",
  comment = NA,
  background = "#E7E7E7",
  prompt = FALSE)

library(tidyverse)
library(MASS)
library(pscl)
library(mediation)
library(broom)
count <- as.tibble(read.table("count_dat.txt", header = TRUE))
count <- count %>%
  mutate(binary = ifelse(Count == 0, 0, 1))
@



\maketitle

\section{Applying and Interpreting Generalized Linear Models}
\subsection{Logit and Probit}
\subsubsection{Binary}
<<include = FALSE>>=
count <- count %>%
  mutate(binary = ifelse(Count == 0, 0, 1))

binary <- glm(binary ~ X1 + X2, family = binomial(link = "logit"), data = count)
summary(binary)

n <- 1000
a <- matrix(1, nrow = n)
b <- matrix(c(seq(-10, 10, length.out = 100)), nrow = n)
c <- matrix(mean(count$X2), nrow = n)
A <- cbind(a,b,c)

B <- matrix(c(binary$coefficients), nrow = 3)
            
probs <- numeric(n)

for(i in 1:n){
  probs[i] <- (exp(A[i, ] %*% B)/(1 + exp(A[i, ] %*% B)))
}
@

In this section, I run an ordinary logistic regression, using the \textit{logit} link function.The estimates, as well as the standard errors and p-values, of the logistic regression model are shown in Table \ref{tab:logit}.

\begin{table}[ht]
\centering
  \begin{tabular}{ccccc}
  \hline
   & Estimate & Std. Error & $z$-value & $p$ \\ 
  \hline
  Intercept & 0.26  & 0.10 & 2.67  & 0.01 \\ 
  $X_{1}$   & -0.60 & 0.10 & -5.84 & 0.00 \\ 
  $X_{2}$   & -0.48 & 0.10 & -4.67 & 0.00 \\ 
  \hline
  \end{tabular}
  \caption{Estimates made using logistic regression}
  \label{tab:logit}
  \end{table}
  
\noindent As can be seen $\beta_{1}$ -- which is the coefficient measuring the effect of $X_{1}$ on the response -- is strongly significant. Meaning that $X_{1}$ can be used to explain a significant share of the variability in the response variable. As for the probabilities, they can be calculated as

  \begin{align} \label{eq:probs}
  P\left(Y=1 | X_{1} = x_{1}, X_{2} = x_{2}\right) =\frac{\exp\left\{ \bm{X} \bm{\beta}\right\}}{1   + \exp\left\{ \bm{X} \bm{\beta}\right\}},
  \end{align}

\noindent where $\bm{X}$ is a matrix containing all covariates, and $\bm{\beta}$ is a vector containing the parameter estimates given in Table \ref{tab:logit}. In order to visualise the change in $P\left(Y=1 | X_{1} = x_{1}, X_{2} = x_{2}\right)$, I fix the value of $X_{2}$ at $\bar{x}_{2}$, and let $X_{1}$ vary on $[-10, 10]$. The different probabilities are shown in Figure \ref{fig:logit}. The figure cleary shows that the conditional probability does not change in a linear manner -- the derivative of the expression given in Equation \ref{eq:probs} is highly non-linear -- meaning that the marginal effect of $X_{1}$ will be different depending what value $X_{1}$ actually takes. In this sense, the odds ratio is a somewhat more intuitive measure, seeing as it is what the model actually assumes to be linear. The odds ratio is defined as

  \begin{align*}
  OR = \exp \left\{ \left( \beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2}\right) - \left( \beta_{0} +       \beta_{1}x_{1}^{*} + \beta_{2}x_{2}\right) \right\},
  \end{align*}

\noindent where $x_{1}^{*}$ is given as the mean of $X_{1}$, while $x_{1}$ is the value found one standard deviation above that same mean. The odds ratio of this particular case is $0.539$, meaning that the odds of $Y$ being equal to 1 decrease by roughly 46 \% when $X_{1}$ increases by one standard deviation. As opposed to the probabilites, this relationship will hold for all values in the domain of $X_{1}$.

\newpage


<<logit, echo = FALSE, fig.align = "center", fig.cap = "The curve shows how the probabilities of the response variable taking the value 1 behave when $X_{1}$ is allowed to vary while $X_{2}$ is kept constant.", fig.height = 3, fig.width = 4, fig.pos = "h!">>=
ggplot(mapping = aes(x = b, y = probs)) + 
  geom_line(color = "blue") +
  labs(x = expression(X[1]),
       y = "Probability")+
  theme_classic()
@

\subsubsection{Categorical}

<<include = FALSE>>=
categorical <- polr(as.factor(Count) ~ X1 + X2, data = count, Hess = TRUE)
summary(categorical)
confint(categorical)

ctable <- coef(summary(categorical))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
ctable <- cbind(ctable, "p value" = p)
ctable      
@

In this task, I fit an ordered-categorical model to the \texttt{count} data set, using \textit{Count} as my response variable, and both $X_{1}$ and $X_{2}$ as covariates. The model output is shown in Table \ref{tab:order-cat} and, as can be seen from the $p$-value column, the coefficient of $X_{2}$ is strongly significant, meaning that it does indeed help in explaining the the variation of the response variable. The response, however, is modeled using the \textit{logit} link, and hence the coefficient of $X_{1}$ means that a one unit increase of the covariate will correspond to a decrease of $0.023$ in the log-odds value of the response. 

Further, the funny looking coefficents are estimates of the change in intercept that is acquired when moving from one category of the response to another. They all show very strong significance, meaning that there are in fact differences in the starting levels of the different categories. Of course, each category will have such an estimate, but I only report the first few in order to save some space. The rest can be found by running the code given in the \texttt{.R} appendix file.


\begin{table}[ht]
\centering
\begin{tabular}{ccccc}
  \hline
          & Estimate & Std. Error & $t$-value & $p$ \\ 
  \hline
  X1      & -0.23041 & 0.08272 & -2.78545 & 0.00535 \\ 
  X2      & -0.25756 & 0.08410 & -3.06238 & 0.00220 \\ 
  0$|$1   & -0.19915 & 0.09259 & -2.15099 & 0.03148 \\ 
  1$|$2   & 0.52305  & 0.09545 & 5.47952  & 0.00000 \\ 
  2$|$3   & 1.16165  & 0.10609 & 10.94936 & 0.00000 \\ 
   \hline
\end{tabular}
\caption{Estimates made using the ordered categorical logit model}
\label{tab:order-cat}
\end{table}

\section{Count}
In this task, I fit a variety of regression models under the assumption that the response variable follows some Poisson distribution. The first model is an ordinary count regression model with no additives, using the logarithmic link function. The output of the model is reported in Table \ref{tab:pois}, which clearly states that $X_{1}$ cannot explain any significant share of the variation of $Y$ ($p>0.05$).

\begin{table}[ht]
\centering
\begin{tabular}{ccccc}
  \hline
  & Estimate & Std. Error & $z$-value & $p$ \\ 
  \hline
  Intercept & 0.49  & 0.04 & 13.81 & 0.00 \\ 
  $X_{1}$   & 0.05  & 0.03 & 1.53  & 0.13 \\ 
  $X_{2}$   & -0.05 & 0.04 & -1.33 & 0.18 \\ 
   \hline
\end{tabular}
\caption{Estimates made using the log-link Poisson regression}
\label{tab:pois}
\end{table}

The second model is a Poisson regression model which tries to take an assumed sense of overdispersion into account. In essence, overdispersion means that the variance of the response does not correspond to the theoretical variance suggested by the distribution assumption. In short, I assume that $Y_{i} \sim Po(\mu_{i})$, meaning that $\text{V}[Y_{i}] = \mu_{i}$. With overdispersion, however, $\text{V}[Y_{i}] > \mu_{i}$, and, because of this, the standard errors of the coefficient estimates need to be adjusted a bit. 

So I fit a model using quasi-likelihood to try and account for the alleged oversispersion, and print the output in Table \ref{tab:quasi-pois}. Comparing Tables \ref{tab:quasi-pois} and \ref{tab:pois}, it is clear that nothing has changed in the column displaying the coefficient estimates. This is a natural outcome of the quasi-likelihood approach. The standard errors, however, are somewhat higher in in Table \ref{tab:quasi-pois}, which is a result of adding a dispersion parameter to model the excess variance shown by the observed response -- $y_{i}$.

\begin{table}[ht]
\centering
\begin{tabular}{ccccc}
  \hline
  & Estimate & Std. Error & $z$-value & $p$ \\ 
  \hline
  Intercept & 0.49  & 0.06 & 8.29 & 0.00 \\ 
  $X_{1}$   & 0.05  & 0.06 & 0.92 & 0.36 \\ 
  $X_{2}$   & -0.05 & 0.06 & -0.80 & 0.43 \\ 
   \hline
\end{tabular}
\caption{Estimates made using quasi-likelihood to control the overdispersion}
\label{tab:quasi-pois}
\end{table}

Neither one of the above mentioned count models result in coefficient estimates that are actually significant, and hence, there is room for some extra troubleshooting. 

Modelling count data, there is always a chance that a great part of the observations are clustered by some particular value of the response -- usually $0$. Plotting $X_{1}$ against the repsonse variable \textit{Count} yields Figure \ref{fig:infl}. The figure shows that observations for all values of $X_{1}$ seem to cluster around 0, suggesting that it might be suitable to use two different models for the data set at hand, with one being binary -- determining whether an observation belings to the \textit{zero class} or not -- and the other being an ordinary count regression. This way of modelling produces what is called a zero-inlfated model, and the output of my attempt at making one is shown in Table \ref{tab:z-count}.

\begin{table}[ht]
\centering
\begin{tabular}{ccccccccc}
  \hline
  & \multicolumn{4}{ c }{\textbf{Count Model}} & \multicolumn{4}{ c }{\textbf{Zero Model}}\\
  \cmidrule(lr){2-5}
  \cmidrule(lr){6-9}
  & Estimate & Std. Error & $z$-value & $p$ & Estimate & Std. Error & $z$-value & $p$ \\ 
  \hline
  Intercept & 1.06 & 0.04 & 27.91 & 0.00 & -0.95 & 0.17 & -5.67 & 0.00 \\ 
  $X_{1}$   & 0.55 & 0.04 & 13.75 & 0.00 & 1.63 & 0.22 & 7.53 & 0.00\\ 
  $X_{2}$   & 0.31 & 0.04 & 7.41 & 0.00  & 1.05 & 0.17 & 6.14 & 0.00\\ 
   \hline
\end{tabular}
\caption{Estimates of the zero-inflated count model}
\label{tab:z-count}
\end{table}

\newpage

Looking at the table, it is clear that the coefficient of $X_{1}$ is significantly positive in both models. The count model states that higher values of $X_{1}$ tend to give higher values of the response variable 

<<infl, echo = FALSE, fig.align = "center", fig.cap = "The figure illustrates the number of observations found in each category of the respobse variable", fig.height = 3, fig.width = 4, fig.pos = "h!">>=
count %>%
  ggplot(mapping = aes(x = Count, y = X1)) +
  geom_point(mapping = aes(alpha = 3), color = "blue") + 
  labs(y = expression(X[1])) + 
  guides(alpha = FALSE) +
  theme_classic()
@



\section{Moderation and Mediation}
<<include = FALSE>>=
med <- as.tibble(read.table("med_dat.txt", header = TRUE))

moderator <- lm(perform ~ negexp*negtone + dysfunc, data = med)

basic <-  lm(perform ~ negexp + negtone + dysfunc, data = med)
n <- seq(min(med$negtone), max(med$negtone), length.out = 100)
y1 <- matrix(mean(med$negexp), nrow = 100)
y2 <- matrix(n, nrow = 100)
y3 <- matrix(mean(med$dysfunc), nrow = 100)
y4 <- matrix(y1*y2, nrow = 100)
Y <- cbind(1,y1,y2,y3,y4)

b1 <- matrix(basic$coefficients, nrow = 4)
b2 <- matrix(moderator$coefficients, nrow = 5)

u <- Y[,1:4] %*% b1
v <- Y %*% b2
@


\subsection{Moderation}
In this section, I fit a moderation model studying the working performance of a given member of a work-team. The model I want to fit strives to determine the performance of a member using a certain set of covariates called \textit{negtone, negexp} and \textit{dysfunc}. Moreover, I want \textit{negexp} to moderate the effect of \textit{negtone} on the response variable, \textit{perform}. In doing so I use
  \begin{align*}
  \text{perform} = \beta_{0} + \beta_{1} \text{dysfunc} + \beta_{2}   \text{negtone} + \beta_{3} \text{negexp} + \beta_{4} \text{negexp}   \cdot \text{negtone}
  \end{align*}
  
\noindent to model the relationship between the response and the covariates, meaning that the interaction term -- $ \text{negexp}   \cdot \text{negtone} $ -- will be the moderator. Fitting the above mentioned model to the data set yields the results shown in Table \ref{tab:mod}.


\begin{table}[h!]
\centering
\begin{tabular}{ccccc}
  \hline
  & Estimate & Std. Error & $z$-value & $p$ \\ 
  \hline
  Intercept   & -0.01 & 0.06 & -0.20 & 0.84 \\ 
  negexp      & -0.02 & 0.12 & -0.16 & 0.87 \\ 
  negtone     & -0.05 & 0.06 & -0.80 & 0.43 \\ 
  dysfunc     &  0.37 & 0.18 & 2.06 & 0.04 \\ 
  Interaction & -0.52 & 0.24 & -2.15 & 0.04 \\ 
   \hline
\end{tabular}
\caption{Regression model estimates, the effect of \textit{negtone} on \textit{perform} is moderated by \textit{negexp}}
\label{tab:mod}
\end{table}


The concept of using a moderator in linear modelling is perhaps best explained through visualisation. Hence, I create a plot visualising the effect of moderation. I fix the values of \textit{negexp} and \textit{dysfunc} at their respective means, and let \textit{negtone} vary on $\left[\min\left(\textit{negtone}\right), \max\left(\textit{negtone}\right) \right]$. Then, I fit a regression model without moderation and compute the fitted values using the coefficient estimates of both models. I then plot the fitted values in the same figure in order to compare the outcomes. The results are shown in figure \ref{fig:mod}.

<<mod, echo = FALSE, fig.align = "center", fig.cap = "The figure illustrates the number of observations found in each category of the respobse variable", fig.height = 3, fig.width = 7, fig.pos = "h!">>=
ggplot() +
  geom_line(mapping = aes(x = n, y = c(u), color = "Ordinary")) +
  geom_line(mapping = aes(x = n, y = c(v), color = "Moderated")) +
  labs(y = "Fitted Value", x = "Negtone") +
  theme_classic()
@





  

\section{Mediation}




  
\end{document}
